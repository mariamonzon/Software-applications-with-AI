{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2CJ4VzeNG4T",
    "outputId": "1bb94f13-2047-493d-c5c0-49fca4be49ef"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnghTizPNWzw"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZkVX1EnNadp"
   },
   "outputs": [],
   "source": [
    "os.chdir( \"/content/gdrive/MyDrive/flair\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FowyHS5ONdSJ",
    "outputId": "8ec3c514-478b-402e-a72d-73d4246ad018"
   },
   "outputs": [],
   "source": [
    "pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDeL2lBkOKXH",
    "outputId": "9c3d949c-78ec-4106-a911-84cc2bb31143"
   },
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "\n",
    "downsample = 1.0 # 1.0 is full data, try a much smaller number like 0.01 to test run the code\n",
    "data_folder = os.getcwd()\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# 1. get the corpus\n",
    "corpus: Corpus = NLPTaskDataFetcher.load_column_corpus(data_folder, columns,\n",
    "                                                             train_file='training_data.csv',\n",
    "                                                             test_file='test_data.csv',\n",
    "                                                           dev_file=None).downsample(downsample)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dCeZKEpOez2"
   },
   "source": [
    "Now, we have loaded __flair__ and our data.<br>\n",
    "Next, we train models for __NER__.<br>\n",
    "Inform yourselves on [Embeddings](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md) in Flair.<br>\n",
    "__Question 1__: What happens when we stack embeddings?<br>\n",
    "How does this influence computational running time and accuracy?<br>\n",
    "What does the __hidden_size__ of the __SequenceTagger__ reference?<br>\n",
    "What happens when you increase/decrease the __hidden_size__?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4aIppbtDOopW"
   },
   "outputs": [],
   "source": [
    "# 4. initialize embeddings. Experiment with different embedding types to see what gets the best results\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings,FlairEmbeddings, CharacterEmbeddings\n",
    "\n",
    "embedding_types = [\n",
    "    WordEmbeddings('glove'),\n",
    "    # comment in this line to use character embeddings\n",
    "    #CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings (needs a LONG time to train :-)\n",
    "    #FlairEmbeddings('news-forward'),\n",
    "    #FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type='ner',\n",
    "                                        use_crf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXvWxWB3PjhP"
   },
   "source": [
    "Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2H7-e-_5Peww",
    "outputId": "1e17ca00-0f23-43de-9414-0f03d1a3641d"
   },
   "outputs": [],
   "source": [
    "# 6. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "model_name = 'flair_glove'\n",
    "\n",
    "trainer.train(model_name,\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=10,\n",
    "              #anneal_with_restarts=True,\n",
    "              max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 882
    },
    "id": "1f_4C828R1nv",
    "outputId": "887a5ad5-eed9-47a9-b7b2-6fabd48770ee"
   },
   "outputs": [],
   "source": [
    "from flair.visual.training_curves import Plotter\n",
    "plotter = Plotter()\n",
    "plotter.plot_training_curves( os.getcwd() + '/flair_all_options/loss.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__: Suggest, how could you improve the F1-value?<br>\n",
    "Are 5 epochs enough for training?<br>\n",
    "How could you speed up computation?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Flair_NER_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
